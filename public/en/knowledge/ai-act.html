<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <title>The EU AI Act Explained – What It Means for Your Organisation | Knowledge Base</title>

  <meta name="description" content="Clear explanation of the EU AI Act: obligations, risk categories, documentation requirements and what public sector organisations need to prepare now.">
  <link rel="canonical" href="https://dutchgovernanceadvisory.nl/en/knowledge/ai-act" />

  <meta property="og:title" content="The EU AI Act Explained – What It Means for Your Organisation">
  <meta property="og:description" content="Overview of obligations, risk classification, documentation and compliance measures under the EU AI Act.">
  <meta property="og:image" content="/assets/images/basbrinkmannwebsitedga.jpg">

  <link rel="stylesheet" href="/styles.css" />
</head>

<body>

<header class="topnav">
  <div class="logo">Bas Brinkmann</div>
  <nav>
    <a href="/en">Home</a>
    <a href="/en/services">Services</a>
    <a href="/en/quickscan">Quick Scan</a>
    <a href="/en/knowledge" class="active">Knowledge Base</a>
    <a href="/en/about">About</a>
    <a href="/en/contact">Contact</a>
    <a href="/">NL</a>
  </nav>
</header>

<section class="page-header">
  <h1>The EU AI Act: What It Means for Your Organisation</h1>
  <p>The most significant regulatory shift for AI in Europe — and what you need to prepare.</p>
</section>

<section class="about">
  <div class="about-content">

    <p>
      The EU AI Act introduces a risk-based regulatory framework for AI.  
      It does not regulate “technology” — it regulates **governance, risk and accountability**.
    </p>

    <p>
      Organisations must understand how their AI systems are classified, what documentation is required,
      and how to ensure continuous monitoring, transparency and oversight.
    </p>

    <h2>Key Obligations Under the AI Act</h2>
    <ul>
      <li>Classification of AI systems (prohibited, high-risk, limited-risk)</li>
      <li>Comprehensive risk management systems</li>
      <li>Human oversight and escalation processes</li>
      <li>Technical documentation and record-keeping</li>
      <li>Transparency and explainability requirements</li>
      <li>Ongoing monitoring and incident reporting</li>
    </ul>

    <h2>What Organisations Should Do Now</h2>
    <p>The earlier you start, the smoother compliance will be. Key first steps:</p>
    <ul>
      <li>Inventory of all AI and algorithmic systems currently in use</li>
      <li>Classify systems according to the AI Act</li>
      <li>Conduct risk and human rights impact assessments</li>
      <li>Develop governance structures and decision-making pathways</li>
      <li>Prepare documentation for supervisory authorities</li>
    </ul>

    <h2>Why This Matters</h2>
    <p>
      The AI Act is not just a legal requirement — it’s a chance to strengthen trust,  
      ensure fairness and create more robust, transparent digital systems that protect public values.
    </p>

  </div>
</section>

<footer>
  <p>© 2025 Bas Brinkmann · AI Governance Consultant</p>
</footer>

</body>
</html>

