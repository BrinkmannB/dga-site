<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <title>Fairness, Bias & Explainability in AI | Knowledge Base</title>

  <meta name="description" content="Understanding fairness, bias, transparency and explainability in AI. Why equal treatment, human oversight and public value protection are essential for responsible AI.">
  <link rel="canonical" href="https://dutchgovernanceadvisory.nl/en/knowledge/fairness" />

  <meta property="og:title" content="Fairness, Bias & Explainability in AI">
  <meta property="og:description" content="Clear insights into discrimination risks, transparency, human rights impact and explainable AI.">
  <meta property="og:image" content="/assets/images/basbrinkmannwebsitedga.jpg">

  <link rel="stylesheet" href="/styles.css" />
</head>

<body>

<header class="topnav">
  <div class="logo">Bas Brinkmann</div>
  <nav>
    <a href="/en">Home</a>
    <a href="/en/services">Services</a>
    <a href="/en/quickscan">Quick Scan</a>
    <a href="/en/knowledge" class="active">Knowledge Base</a>
    <a href="/en/about">About</a>
    <a href="/en/contact">Contact</a>
    <a href="/">NL</a>
  </nav>
</header>

<section class="page-header">
  <h1>Fairness, Bias & Explainability in AI</h1>
  <p>Why fairness and transparency lie at the heart of trustworthy AI.</p>
</section>

<section class="about">
  <div class="about-content">

    <p>
      AI systems influence real people, decisions and opportunities.  
      Fairness is not a technical detail — it is a cornerstone of legitimacy,  
      equality and public trust. Organisations must ensure that AI outcomes  
      are understandable, justifiable and free from unjustified discrimination.
    </p>

    <h2>What Fairness Means in AI</h2>
    <p>
      Fairness refers to the absence of unjustified differences in outcomes  
      between groups. What is considered “fair” depends heavily on context,  
      societal norms and the goals of the system.
    </p>

    <h2>Types of Bias</h2>
    <ul>
      <li><strong>Dataset Bias:</strong> skewed or incomplete training data that disadvantages specific groups</li>
      <li><strong>Model Bias:</strong> behaviour of the AI model that amplifies differences</li>
      <li><strong>Contextual Bias:</strong> using a model in a context different from what it was designed for</li>
      <li><strong>User Bias:</strong> misinterpretation of AI outputs by humans</li>
    </ul>

    <h2>Why Explainability Matters</h2>
    <p>
      Without explainability, users cannot understand or contest AI decisions.  
      Transparency supports trust, effective oversight and legal compliance —  
      and is required under the EU AI Act.
    </p>

    <h2>Transparency Requirements Under the AI Act</h2>
    <ul>
      <li>Clear explanations of model behaviour and limitations</li>
      <li>Documentation of risks, assumptions and mitigation steps</li>
      <li>Traceability of data and decision-making</li>
      <li>Human oversight and intervention possibilities</li>
    </ul>

    <h2>How Organisations Can Ensure Fairness</h2>
    <ul>
      <li>Measure bias using fairness metrics</li>
      <li>Use datasheets & model cards for documentation</li>
      <li>Engage stakeholders and diverse user groups</li>
      <li>Define clear oversight and escalation processes</li>
      <li>Implement explainability for end-users, not only developers</li>
    </ul>

    <p>
      Fairness and explainability are at the core of responsible AI —  
      they determine whether AI systems support public values and  
      uphold human rights.
    </p>

  </div>
</section>

<footer>
  <p>© 2025 Bas Brinkmann · AI Governance Consultant</p>
</footer>

</body>
</html>

